{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_n6_idxzPsMv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.regularizers import l2\n",
        "import tensorflow as tf\n",
        "import math\n",
        "import statistics\n",
        "import keras\n",
        "from tensorflow.python.ops import math_ops\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LXeLXl2QjuXr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "79c14f1f-5ba6-4ecb-f83d-83075a80e491"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-9363b5dc6392>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdfs_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./pojutrze_24h_uzupelnianie_srednia_train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdfs_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfs_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdfs_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./pojutrze_24h_test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdfs_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfs_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtwo_dfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfs_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './pojutrze_24h_test.csv'"
          ]
        }
      ],
      "source": [
        "dfs_train = pd.read_csv('./pojutrze_24h_uzupelnianie_srednia_train.csv')\n",
        "dfs_train = dfs_train.iloc[: , 1:]\n",
        "dfs_test = pd.read_csv('./pojutrze_24h_test.csv')\n",
        "dfs_test = dfs_test.iloc[: , 1:]\n",
        "two_dfs = dfs_train.append(dfs_test, ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJM3WrLknn_9"
      },
      "source": [
        "### Prepare data for temperature regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1C_pBC67SpHH"
      },
      "outputs": [],
      "source": [
        "# NUMBER_OF_Y_COLUMNS = 3\n",
        "# CHOSEN_Y_COLUMN = 3 # temp5\n",
        "\n",
        "# df_shuffle_train = dfs_train.sample(frac = 1)\n",
        "\n",
        "# Xs_train = df_shuffle_train.iloc[: , :-NUMBER_OF_Y_COLUMNS]\n",
        "# X_norm_train = Xs_train\n",
        "# X_norm_train = (Xs_train-Xs_train.mean())/Xs_train.std()\n",
        "# X_norm_train = X_norm_train.replace(np.nan, 0)\n",
        "\n",
        "\n",
        "# x_train = X_norm_train.iloc[: , :]\n",
        "# y_train = df_shuffle_train.iloc[: , -CHOSEN_Y_COLUMN:-(CHOSEN_Y_COLUMN - 1)]\n",
        "\n",
        "\n",
        "# df_shuffle_test = dfs_test.sample(frac = 1)\n",
        "\n",
        "# Xs_test = df_shuffle_test.iloc[: , :-NUMBER_OF_Y_COLUMNS]\n",
        "# X_norm_test = Xs_test\n",
        "# X_norm_test = (Xs_test-Xs_test.mean())/Xs_test.std()\n",
        "# X_norm_test = X_norm_test.replace(np.nan, 0)\n",
        "\n",
        "\n",
        "# x_test = X_norm_test.iloc[: , :]\n",
        "# y_test = df_shuffle_test.iloc[: , -CHOSEN_Y_COLUMN:-(CHOSEN_Y_COLUMN - 1)]\n",
        "\n",
        "################################################################################################# wspolna standaryzacja na polaczonym zbiorze\n",
        "\n",
        "NUMBER_OF_Y_COLUMNS = 3\n",
        "CHOSEN_Y_COLUMN = 1 # temp5\n",
        "\n",
        "df_shuffle_train = dfs_train.sample(frac = 1)\n",
        "\n",
        "Xs_train = df_shuffle_train.iloc[: , :-NUMBER_OF_Y_COLUMNS]\n",
        "X_norm_train = Xs_train\n",
        "X_norm_train = (Xs_train-two_dfs.iloc[: , :-NUMBER_OF_Y_COLUMNS].mean())/two_dfs.iloc[: , :-NUMBER_OF_Y_COLUMNS].std()\n",
        "X_norm_train = X_norm_train.replace(np.nan, 0)\n",
        "\n",
        "\n",
        "x_train = X_norm_train.iloc[: , :]\n",
        "y_train = df_shuffle_train.iloc[: , -CHOSEN_Y_COLUMN:-(CHOSEN_Y_COLUMN - 1)]\n",
        "\n",
        "if CHOSEN_Y_COLUMN == 1:\n",
        "  y_train = df_shuffle_train.iloc[: , -1]\n",
        "\n",
        "\n",
        "df_shuffle_test = dfs_test.sample(frac = 1)\n",
        "\n",
        "Xs_test = df_shuffle_test.iloc[: , :-NUMBER_OF_Y_COLUMNS]\n",
        "X_norm_test = Xs_test\n",
        "X_norm_test = (Xs_test-two_dfs.iloc[: , :-NUMBER_OF_Y_COLUMNS].mean())/two_dfs.iloc[: , :-NUMBER_OF_Y_COLUMNS].std()\n",
        "X_norm_test = X_norm_test.replace(np.nan, 0)\n",
        "\n",
        "\n",
        "x_test = X_norm_test.iloc[: , :]\n",
        "y_test = df_shuffle_test.iloc[: , -CHOSEN_Y_COLUMN:-(CHOSEN_Y_COLUMN - 1)]\n",
        "\n",
        "if CHOSEN_Y_COLUMN == 1:\n",
        "  y_test = df_shuffle_test.iloc[: , -1]\n",
        "\n",
        "############################################################################################## bez standaryzacji\n",
        "\n",
        "# NUMBER_OF_Y_COLUMNS = 3\n",
        "# CHOSEN_Y_COLUMN = 3 # temp5\n",
        "\n",
        "# df_shuffle_train = dfs_train.sample(frac = 1)\n",
        "\n",
        "# Xs_train = df_shuffle_train.iloc[: , :-NUMBER_OF_Y_COLUMNS]\n",
        "# X_norm_train = Xs_train\n",
        "\n",
        "\n",
        "# x_train = X_norm_train.iloc[: , :]\n",
        "# y_train = df_shuffle_train.iloc[: , -CHOSEN_Y_COLUMN:-(CHOSEN_Y_COLUMN - 1)]\n",
        "\n",
        "\n",
        "# df_shuffle_test = dfs_test.sample(frac = 1)\n",
        "\n",
        "# Xs_test = df_shuffle_test.iloc[: , :-NUMBER_OF_Y_COLUMNS]\n",
        "# X_norm_test = Xs_test\n",
        "\n",
        "\n",
        "# x_test = X_norm_test.iloc[: , :]\n",
        "# y_test = df_shuffle_test.iloc[: , -CHOSEN_Y_COLUMN:-(CHOSEN_Y_COLUMN - 1)]\n",
        "\n",
        "################################################################################################## nie pamietam\n",
        "\n",
        "\n",
        "# NUMBER_OF_Y_COLUMNS = 3\n",
        "# CHOSEN_Y_COLUMN = 3 # temp5\n",
        "\n",
        "# df_shuffle_train = dfs_train.sample(frac = 1)\n",
        "\n",
        "# Xs_train = df_shuffle_train.iloc[: , :-NUMBER_OF_Y_COLUMNS]\n",
        "# X_norm_train = Xs_train\n",
        "# # X_norm_train = (Xs_train-Xs_train.mean())/Xs_train.std()\n",
        "# # X_norm_train = X_norm_train.replace(np.nan, 0)\n",
        "\n",
        "\n",
        "# x_train = X_norm_train.iloc[: , :]\n",
        "# y_train = df_shuffle_train.iloc[: , -CHOSEN_Y_COLUMN:-(CHOSEN_Y_COLUMN - 1)]\n",
        "\n",
        "\n",
        "# df_shuffle_test = dfs_test.sample(frac = 1)\n",
        "\n",
        "# Xs_test = df_shuffle_test.iloc[: , :-NUMBER_OF_Y_COLUMNS]\n",
        "# X_norm_test = Xs_test\n",
        "# # X_norm_test = (Xs_test-Xs_test.mean())/Xs_test.std()\n",
        "# # X_norm_test = X_norm_test.replace(np.nan, 0)\n",
        "\n",
        "\n",
        "# x_test = X_norm_test.iloc[: , :]\n",
        "# y_test = df_shuffle_test.iloc[: , -CHOSEN_Y_COLUMN:-(CHOSEN_Y_COLUMN - 1)]\n",
        "\n",
        "######################################################################################################## podzial danych treningowych na test i train\n",
        "\n",
        "# df_shuffle = dfs_train.sample(frac = 1)\n",
        "\n",
        "# train_length = math.floor(df_shuffle.shape[0] * 0.8)\n",
        "\n",
        "# Xs = df_shuffle.iloc[: , :-1]\n",
        "# X_norm = Xs\n",
        "# X_norm = (Xs-Xs.mean())/Xs.std()\n",
        "# X_norm = X_norm.replace(np.nan, 0)\n",
        "\n",
        "# x_test = X_norm.iloc[train_length: , :]\n",
        "# y_test = df_shuffle.iloc[train_length: , -3:-2]\n",
        "# x_train = X_norm.iloc[:train_length , :]\n",
        "# y_train = df_shuffle.iloc[:train_length , -3:-2]\n",
        "\n",
        "######################################################################################################### podzial danych testowych na test i train\n",
        "\n",
        "# df_shuffle = dfs_test.sample(frac = 1)\n",
        "\n",
        "# train_length = math.floor(df_shuffle.shape[0] * 0.8)\n",
        "\n",
        "# Xs = df_shuffle.iloc[: , :-1]\n",
        "# X_norm = Xs\n",
        "# X_norm = (Xs-Xs.mean())/Xs.std()\n",
        "# X_norm = X_norm.replace(np.nan, 0)\n",
        "\n",
        "# x_test = X_norm.iloc[train_length: , :]\n",
        "# y_test = df_shuffle.iloc[train_length: , -3:-2]\n",
        "# x_train = X_norm.iloc[:train_length , :]\n",
        "# y_train = df_shuffle.iloc[:train_length , -3:-2]\n",
        "\n",
        "######################################################################################################### podzial danych polaczonych na test i train\n",
        "\n",
        "# df_shuffle = two_dfs.sample(frac = 1)\n",
        "\n",
        "# train_length = math.floor(df_shuffle.shape[0] * 0.8)\n",
        "\n",
        "# Xs = df_shuffle.iloc[: , :-1]\n",
        "# X_norm = Xs\n",
        "# X_norm = (Xs-Xs.mean())/Xs.std()\n",
        "# X_norm = X_norm.replace(np.nan, 0)\n",
        "\n",
        "# x_test = X_norm.iloc[train_length: , :]\n",
        "# y_test = df_shuffle.iloc[train_length: , -3:-2]\n",
        "# x_train = X_norm.iloc[:train_length , :]\n",
        "# y_train = df_shuffle.iloc[:train_length , -3:-2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr9uFOz8Yk4l"
      },
      "source": [
        "Regresja MSE temperatura 5000 danych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqViV9aXddFj"
      },
      "outputs": [],
      "source": [
        "def correctly_predicted(predicted, y_test):\n",
        "  counter = 0\n",
        "  for i in range(len(predicted)):\n",
        "    if abs(predicted[i] -  y_test[i]) <= 2:\n",
        "      counter+=1\n",
        "\n",
        "  return counter\n",
        "\n",
        "def test_loss_function(loss):\n",
        "  dim = x_test.shape[1]\n",
        "  lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "      initial_learning_rate=0.1,\n",
        "      decay_steps=100,\n",
        "      decay_rate=0.9)\n",
        "  adam = tf.keras.optimizers.Adam(\n",
        "      learning_rate=lr_schedule)\n",
        "  # adam = tf.keras.optimizers.Adam(\n",
        "  #     learning_rate=0.00000001)\n",
        "  model = Sequential()\n",
        "  model.add(Dense(12, input_dim=dim, activation='relu'))\n",
        "  model.add(Dense(10, activation='relu'))\n",
        "  # model.add(Dropout(0.2))\n",
        "  model.add(Dense(10, activation='relu'))\n",
        "  # model.add(Dropout(0.2))\n",
        "  model.add(Dense(1, activation='relu'))\n",
        "  model.compile(loss=loss, optimizer=adam)\n",
        "  model.fit(x=x_train, y=y_train, epochs=50, verbose=0)\n",
        "  # model.fit(x=x_train, y=y_train, epochs=50)\n",
        "  predicted = model.predict(x_test)\n",
        "  return predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIvpg0bQ4aJ6",
        "outputId": "a40152d8-afd7-44f7-8881-8415be451422"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'keras.losses.MeanSquaredError'>  finished\n",
            "5562 0.4491641766938545\n"
          ]
        }
      ],
      "source": [
        "losses = [\n",
        "          tf.keras.losses.MeanSquaredError(),\n",
        "          tf.keras.losses.MeanAbsoluteError(),\n",
        "          tf.keras.losses.Huber(),\n",
        "          tf.keras.losses.LogCosh(),\n",
        "          tf.keras.losses.MeanAbsolutePercentageError(),\n",
        "          tf.keras.losses.MeanSquaredLogarithmicError(),\n",
        "          tf.keras.losses.CosineSimilarity(),\n",
        "          ]\n",
        "\n",
        "predictions = []\n",
        "\n",
        "for loss in losses:\n",
        "  new_preds = test_loss_function(loss)\n",
        "  predictions.append(new_preds)\n",
        "  correct_predictions = correctly_predicted(new_preds.flatten(),  y_test.iloc[:,0].tolist())\n",
        "  print(type(loss), ' finished')\n",
        "  print(correct_predictions, correct_predictions / len(new_preds))\n",
        "\n",
        "for i in range(len(predictions)):\n",
        "  correct_predictions = correctly_predicted(predictions[i].flatten(),  y_test.iloc[:,0].tolist())\n",
        "  print(type(losses[i]), '    ', correct_predictions, correct_predictions / len(predictions[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geQZN-bvnoAJ",
        "outputId": "6bff1d0b-ed75-42b9-d24d-d4dcbf159c9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "value from last measure      6222 0.5024630541871922\n"
          ]
        }
      ],
      "source": [
        "# porownanie z trzecim dniem\n",
        "\n",
        "predictions = Xs_test.iloc[: , -6].tolist() # temp\n",
        "\n",
        "correct_predictions = correctly_predicted(predictions,  y_test.iloc[:,0].tolist())\n",
        "print('value from last measure', '    ', correct_predictions, correct_predictions / len(predictions))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHnRJ9UzZtZt"
      },
      "outputs": [],
      "source": [
        "def custom_loss(y_true, y_pred):\n",
        "  counter = 0\n",
        "  for i in range(len(y_pred)):\n",
        "    if abs(y_pred[i] -  y_true[i]) > 2:\n",
        "      counter+=1\n",
        "  return counter/len(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FOXv3ShwUrX"
      },
      "outputs": [],
      "source": [
        "print(y_train.head(20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVr3AYJKrMkE"
      },
      "outputs": [],
      "source": [
        "dim = x_test.shape[1]\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=dim, activation='sigmoid'))\n",
        "model.add(Dense(10, activation='sigmoid'))\n",
        "model.add(Dense(10, activation='sigmoid'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy',\n",
        "              metrics=['accuracy']) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx7tE0JfpqPA",
        "outputId": "f070532f-95cb-4fd5-b482-6d03db6972b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9062     0\n",
              "22390    0\n",
              "24908    0\n",
              "31879    1\n",
              "14019    0\n",
              "Name: Wind5_class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Wg25otE0ycp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "10a14549-2b61-4df5-e1c9-f108a1b30c1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-b329068ec86b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
          ]
        }
      ],
      "source": [
        "model.fit(x=x_train, y=y_train.values, epochs=50)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "sieci_test_nowych_danych.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}